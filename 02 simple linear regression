 02
 import tensorflow as tf
import numpy as np
tf.enable_eager_execution()

# Data
x_data = [1, 2, 3, 4, 5] # x데이터 값
y_data = [1, 2, 3, 4, 5] # y데이터 값 

# W, b initialize
W = tf.Variable(2.9)
b = tf.Variable(0.5)

# W, b update
for i in range(100):
    # Gradient descent # 경사하강법 사용
    with tf.GradientTape() as tape:
        hypothesis = W * x_data + b
        cost = tf.reduce_mean(tf.square(hypothesis - y_data)) # 감소값 평균
    W_grad, b_grad = tape.gradient(cost, [W, b])
    W.assign_sub(learning_rate * W_grad) # 파라미터 업데이트
    b.assign_sub(learning_rate * b_grad) # 파라미터 
    if i % 10 == 0:
      print("{:5}|{:10.4f}|{:10.4f}|{:10.6f}".format(i, W.numpy(), b.numpy(), cost))

print()

# predict
print(W * 5 + b) # W가 5일때 예측값
print(W * 2.5 + b) # W가 2.5일 때 예측값



